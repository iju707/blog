{"/blog/20230921-reactjs/":{"data":{"":"","문제점#문제점":"ReactJS로 프로젝트를 시작하면, 보통 create-react-app을 사용합니다. 개발을 하고 시작을 하려면 다음과 같은 명령을 실행하게 됩니다.\n$ yarn run start 그러면 http://localhost:3000으로 페이지가 열리게 됩니다. 환경에 따라 다른 포트로 실행하고 싶습니다.","해결방법#해결방법":"Start Script 수정하기 실제 start 스크립트를 보면 다음과 같이 포트를 설정하고 있습니다.\nconst DEFAULT_PORT = parseInt(process.env.PORT, 10) || 3000; 따라서 package.json 파일에서 scripts 부분의 start에 PORT 환경변수 설정을 추가합니다. 여기서는 Windows환경에서 set을 활용하여 9090포트로 변경하겠습니다.\n{ ... \"scripts\": { \"start\": \"set PORT=9090 \u0026\u0026 react-scripts start\", ... }, ... } Linux의 경우에는 export를 활용하시면 됩니다.\n{ ... \"scripts\": { \"start\": \"export PORT=9090 \u0026\u0026 react-scripts start\", ... }, ... } Mac의 경우에는 다음과 같습니다.\n{ ... \"scripts\": { \"start\": \"PORT=9090 react-scripts start\", ... }, ... } .env 파일 활용하기 다음 방법은 .env 파일을 사용하면 됩니다. 프로젝트 상위 디렉터리에 .env 파일을 생성하고 다음과 같이 입력합니다.\nPORT=9090 "},"title":"[ReactJS] create-react-app의 실행 포트 변경"},"/blog/20230921-windows-failover/":{"data":{"":"","문제점#문제점":"MSSQL MSCS를 구성하기 위해 장애조치(Failover) 클러스터를 구성하려고 하였습니다.\n만들기 과정에서 계속 실패가 발생했고 원인을 알 수 없었습니다.","원인확인#원인확인":"이벤트 뷰어에서 관리자 이벤트를 살펴보았습니다. Cluster Service가 시작이 불가능했고 Service Control Manager에서 7024 오류가 발생하였습니다.\nCluster Service 서비스가 서비스 특정 오류 로그온 실패 : 사용자는 이 컴퓨터에서는 요청된 로그온 유형을 허가받지 않았습니다. 때문에 종료되었습니다. 로그인에 문제가 있을 것 같아서 Windows 로그의 보안 로그를 확인했습니다. 내용을 보니 감사 실패 - 4625 가 발생하였고 상세 내용중 다음이 있었습니다.\n로그온을 실패한 계정 계정 이름 CLIUSR ","해결방법#해결방법":"CLIUSR 계정은 클러스터를 구성할 때 자동으로 생성되는 계정으로 원격지에서 로그인 할 수 있는 권한이 누락된지 확인했습니다. 로컬 보안 정책 에서 로컬 정책 \u003e 사용자 권한 할당 메뉴로 가면 네트워크에서 이 컴퓨터 액세스 정책 있습니다. 저의 경우 일반적인 보안으로 인하여 Administrators 그룹만 있었습니다. 여기에 Authenticated Users를 추가하고 다시 클러스터를 생성하니 정상처리되었습니다."},"title":"[Windows] Failover Cluster 생성실패 (로그온 실패)"},"/blog/20230923-git-proxy/":{"data":{"":"","gitconfig-파일-확인#.gitconfig 파일 확인":"Git에서 config 명령을 수행하면 일반적으로 .gitconfig 파일을 생성하게 됩니다. 위치는 보통 사용자홈디렉터리에 있습니다. (예: Windows의 경우 C:\\Users\\user\\.gitconfig) 위와 같이 명령을 실행하였을 경우 다음과 같습니다.\n[http] proxy = http://128.0.0.1:8080 sslVerify = false [http \"https://code.oofbird.me\"] proxy = ","개요#개요":"Git을 사내에서 사용하다보면 일반적으로 프록시 문제를 경험하게 됩니다.\n왠만한 기업에서는 보안을 이유로 프록시를 도입하여 네트워크가 구성되어있기 때문입니다.\n그런데, 프록시를 설정해놓으면 구성에 따라 내부 Git Repository에 접속하지 못하는 사태가 발생하게 됩니다.\n아래 내용을 통하여 외부는 프록시를, 내부는 다이렉트로 접근하는 방법을 설정해보겠습니다.","내부-git-repository-proxy-설정#내부 Git Repository Proxy 설정":"보통 내부 Git Repository는 프록시네트워크 안쪽에 위치하므로 Proxy 예외처리를 진행하게 됩니다. Git에서는 http.\u003curl\u003e.* 을 사용하여 특정 URL에 설정을 지정할 수 있게 되어있습니다. 예시로 https://code.oofbird.me 를 Git Repository라고 할 경우 다음과 같이 Proxy를 공백으로 설정하시면 됩니다.\n$ git config --global http.https://code.oofbird.me.proxy \"\" ","외부-proxy-설정#외부 Proxy 설정":"기본적으로 Git은 http_proxy, https_proxy, all_proxy 와 같은 환경변수를 사용하여 프록시 설정을 구성합니다. 별도 지정할 경우 http.proxy 설정을 추가합니다.\n$ git config --global http.proxy [protocol://][user[:password]@]proxyhost[:port] // http://128.0.0.1:8080 일 경우 $ git config --global http.proxy http://128.0.0.1:8080 추가적으로 대부분의 사이트는 HTTPS를 사용하며 보통 프록시를 통과할 경우 인증서검증에 실패할 가능성이 있습니다. 이것을 우회하기 위해 http.sslVerify 설정을 추가합니다.\n$ git config --global http.sslVerify false "},"title":"[Git] Proxy 설정하기"},"/blog/20230923-synology-eac3/":{"data":{"":"","개요#개요":"Video Station에서 영상을 재생할 때 간헐적으로 지원되지 않는 오디오 코덱으로 안되는 경우가 있습니다. 원인을 찾아보면 특허 문제로 인하여 공식 지원이 불가능한 경우입니다.\nVideo Station 에서 DTS 또는 EAC3 오디오 형식의 비디오를 재생할 수 없는 이유는 무엇입니까?\n현재 Video Station 은 특허 라이센스 문제로 인해 다음과 같은 오디오 형식을 재생할 수 없습니다.\nDTS 및 DTS-HD를 포함하되 이에 국한되지 않고 모든 DTS 오디오 형식 부분적인 돌비 디지털 오디오 형식(Dolby Digital Plus(EAC3) 및 돌비 TrueHD를 포함하되 이에 국한되지 않음) ","해결방법#해결방법":"아래와 같이 설정하면 장치가 재부팅할때 마다 스크립트가 실행됩니다. 따라서 DSM이 업데이트되더라도 계속적으로 적용이 가능합니다.\n커뮤니티 패키지 소스 설정하기 패키지 센터 \u003e 설정 을 클릭한 뒤 패키지 소스 탭에서 다음과 같이 입력합니다.\n위치 : https://packages.synocommunity.com/\nFFMPEG 패키지를 설치하기 패키지 소스 설정이 완료되면 왼쪽에 커뮤니티 메뉴가 추가되며 그곳에서 ffmpeg를 설치합니다. (4~6 버전 무관)\n작업 스케쥴러 생성하기 제어판 \u003e 서비스 \u003e 작업 스케쥴러 메뉴에서 생성 \u003e 트리거된 작업 \u003e 사용자 정의 스크립트 를 클릭합니다.\n일반 설정 탭에서 사용자는 root, 이벤트는 부트업 으로 설정합니다.\n작업 설정 탭의 실행 명령에서 다음을 입력합니다. 이때 FFMEPG VERSION은 설치한 버전에 맞게 선택합니다. (예: 6)\ncurl https://raw.githubusercontent.com/AlexPresso/VideoStation-FFMPEG-Patcher/main/patcher.sh | bash -s -- \u003cFFMEPG Version\u003e 적용하기 작업 스케줄러 목록에서 생성한 대상을 선택 후 마우스 오른쪽 \u003e 실행 버튼을 클릭합니다.\n결과는 대상 선택 후 상단의 작업 \u003e 결과 보기 로 확인할 수 있습니다.\n참고 : https://github.com/AlexPresso/VideoStation-FFMPEG-Patcher"},"title":"[Synology] EAC3 코덱 재생하기"},"/blog/20230927-mariadb/":{"data":{"":"","format#Format":"주요 형식은 다음과 같습니다.\n옵션 설명 %Y 4자리 년도 (예: 2021) %y 2자리 년도 (예: 21) %m 2자리 월 (예: 01) %d 2자리 일 (예: 01) %H 2자리 시간 (00 ~ 23) %h 2자리 시간 (01 ~ 12) %i 2자리 분 %S 2자리 초 ","개요#개요":"MariaDB에서 문자열을 날짜형으로 변경하는 방법입니다.","문법#문법":" STR_TO_DATE(str, format) str은 날짜로 전환할 문자열이며, format은 문자열의 형식입니다.","예시#예시":" SELECT STR_TO_DATE('20200101 23:59:59', '%Y%m%d %H:%i%S') 2020-01-01 23:59:59 "},"title":"[MariaDB] 문자열을 날짜로 STR_TO_DATE"},"/blog/20230927-postgresql/":{"data":{"":"","pg_ctl-이용#pg_ctl 이용":"pg_ctl에서는 다음방법으로 설정로딩을 지원합니다.\n$ pg_ctl reload [-s] [-D datadir] 옵션은\n-s : 오류 관련 메시지만 출력합니다. -D datadir : PostgreSQL이 사용하는 데이터 경로를 지정합니다. ","query-이용#Query 이용":"SQL 내에서도 설정로딩을 할 수 있습니다.\nSELECT PG_RELOAD_CONF(); ","개요#개요":"PostgreSQL은 다양한 설정을 파일로 다루고 있습니다.\n그중 pg_hba.conf 파일로 접근제어를 하게 되는데 운영중 수정이 필요한 상황이 발생했을 때 재시작 없이 적용하는 방법을 가이드 합니다.","제약사항#제약사항":"일반적인 설정은 재적용이 가능하나, 일부 재시작이 필요한 설정은 적용되지 않습니다."},"title":"[PostgreSQL] 재시작없이 설정불러오기 (reload configuration without restart)"},"/blog/20231012-core_autocrlf/":{"data":{"":"","원인#원인":"MacOS 환경에서는 정상이었으나 Windows에서 문제가 발생하였다는 점에 빌드나 배포를 점검하였습니다.\nGit에서 commit 하는 메시지 중 다음을 발견하였습니다.\nPS C:\\workspace\\blog\u003e .\\upload.bat Initialized empty Git repository in C:/workspace/blog/public/.git/ warning: in the working copy of '404.html', CRLF will be replaced by LF the next time Git touches it warning: in the working copy of 'blog/index.xml', CRLF will be replaced by LF the next time Git touches it warning: in the working copy of 'boto3/example/index.html', CRLF will be replaced by LF the next time Git touches it warning: in the working copy of 'boto3/example/index.xml', CRLF will be replaced by LF the next time Git touches it warning: in the working copy of 'boto3/example/s3/index.xml', CRLF will be replaced by LF the next time Git touches it warning: in the working copy of 'boto3/example/s3/presigned-urls/index.html', CRLF will be replaced by LF the next time Git touches it 내용인즉슨 windows에서 사용하는 줄내림(CRLF, \\r\\n)를 Linux/Mac용(LF, \\n)로 변경하는 것 입니다. 이로 인하여 빌드시점의 파일과 형상에 업로드된 파일이 바뀌게 된 것 입니다.","해결책#해결책":"배포할 때 줄내림을 바꾸지 않도록 git에 설정을 하였습니다.\ngit config core.autocrlf false\n일반적으로 권장되지 않는 옵션이지만, 위와 같이 특수한 상황인 경우 적용이 필요합니다.","현상#현상":"Hugo를 활용하여 Github Page에 블로그를 생성하였습니다. 기존 MacOS환경에서는 큰 문제가 없었는데 Windows 환경으로 오고나서 배포를 하니 버튼동작이 하지 않고 크롬콘솔에서 다음과 같이 오류가 발생하였습니다.\nFailed to find a valid digest in the ‘integrity’ attribute for resource ‘….’ with computed SHA-256 integrity ‘….’. The resource has been blocked.\n내용상 파일의 digest가 일치하지 않아 차단처리를 한 것으로 보입니다."},"title":"[Git] Failed to find a valid digest in the \"integrity\" attribute for resource"},"/blog/20231012-git-submodule/":{"data":{"":"","개요#개요":"Git 프로젝트에서 다른 Repository를 모듈로 참조할 경우 Submodule로 등록합니다.\n아래는 기존의 프로젝트를 Clone할 때 Submodule을 어떻게 처리해야하는지 안내합니다.","방법-1--개별-초기화#방법 1 : 개별 초기화":"먼저 git submodule init 명령으로 submodule을 초기화 합니다.\n$ git submodule init Submodule 'themes/hextra' (https://github.com/imfing/hextra.git) registered for path 'themes/hextra' git submodule update 로 최신 형상으로 업데이트 합니다.\n$ git submodule update Cloning into 'C:/workspace/blog/themes/hextra'... Submodule path 'themes/hextra': checked out '28a20e1e7e2e90dc128a3439bf88c1ecccff9220' ","방법-2--clone시-옵션주기#방법 2 : Clone시 옵션주기":"Clone을 할 때 --recurse-submodules 옵션을 추가하면 됩니다. 그러면 형상을 Clone하면서 Submodule 까지 포함하여 진행합니다.\n$ git clone --recurse-submodules https://github.com/iju707/blog.git Cloning into 'blog'... remote: Enumerating objects: 448, done. remote: Counting objects: 100% (448/448), done. remote: Compressing objects: 100% (203/203), done. Receiving objects: 87% (390/448)used 418 (delta 150), pack-reused 0 Receiving objects: 100% (448/448), 852.84 KiB | 35.53 MiB/s, done. Resolving deltas: 100% (176/176), done. Submodule 'themes/hextra' (https://github.com/imfing/hextra.git) registered for path 'themes/hextra' Cloning into 'C:/workspace/test/blog/themes/hextra'... remote: Enumerating objects: 1781, done. remote: Counting objects: 100% (413/413), done. remote: Compressing objects: 100% (121/121), done. remote: Total 1781 (delta 327), reused 312 (delta 288), pack-reused 1368 Receiving objects: 100% (1781/1781), 3.02 MiB | 29.17 MiB/s, done. Resolving deltas: 100% (1017/1017), done. Submodule path 'themes/hextra': checked out '28a20e1e7e2e90dc128a3439bf88c1ecccff9220' "},"title":"[Git] Submodule이 있는 저장소 Clone 하기"},"/blog/20231013-sysctl-reload/":{"data":{"":"","개요#개요":"Linux 환경에 Elasticsearch를 설치하는데 시스템 설정 수정이 필요합니다. (vm.max_map_count)\n다만, 운영환경이고 별도절차가 있어서 재부팅하기 쉽지 않습니다.\n재부팅하지 않고 sysctl로 설정한 내용을 다시 읽는 법을 공유합니다.","다시읽기#다시읽기":"아래 명령을 수행하면 재부팅없이 다시 읽게 됩니다. 필요시 sudo가 요구됩니다.\n$ sysctl --system ","다시읽은-파일#다시읽은 파일":"위 명령을 실행하면 아래의 파일을 다시 읽게 됩니다.\n/run/sysctl.d/*.conf /etc/sysctl.d/*.conf /usr/local/lib/sysctl.d/*conf /usr/lib/sysctl.d/*.conf /lib/sysctl.d/*conf /etc/sysctl.conf "},"title":"[Linux] 재부팅없이 sysctl 설정 다시읽기(reload)"},"/blog/20231028-python-op/":{"data":{"":"","방법-1--eval#방법 1 : eval":"단순하게 if를 사용해도 eval 을 사용해도 됩니다.\n\u003e\u003e eval(\"3 + 2\") 5 그런데 eval의 경우에는 원하는 용도 이외에도 처리해버리기 때문에 위험합니다.","방법-2--operator#방법 2 : operator":"python에서는 operator 라는 패키지를 제공합니다. 이것을 활용하여 연산처리를 진행하면 됩니다.\nimport operator ops = { \"+\": operator.add, \"-\": operator.sub, \"*\": operator.mul, \"/\": operator.truediv } input = \"3 + 2\" split_input = input.split(\" \") print(ops[input[1]](input[0], input[2])) # 5 operator에서 지원하는 연산자 목록은 아래를 참고하세요.\nhttps://docs.python.org/ko/3/library/operator.html","원하는-것#원하는 것":"문자열로 연산식을 받고 이것에 대한 계산결과를 보고 싶습니다. 예로 3 + 2 를 받으면 5 이라는 결과를 받고 싶습니다."},"title":"[Pyhon] 문자열을 연산자로 사용하기"},"/blog/20231228-vmware-ctrix/":{"data":{"":"","방법-1---vmware에서-accelerate-3d-graphics-끄기#방법 1 - VMware에서 \u003ccode\u003eAccelerate 3D Graphics\u003c/code\u003e 끄기":"현재 환경 Macbook Pro M3pro VMware Fusion Player 13.5.0 Windows 11 arm Ctrix Workspace 23.9.1.104 (2309.1) 상황 현재 Ctrix Workspace를 사용하여 가상 데스크톱 인프라(VDI)를 구축하고 접속해서 업무를 진행하고 있습니다. 최근 맥북으로 변경하고 VMware를 사용하여 Windows 11 arm 버전을 설치한 뒤 접속하였는데 너무 반응속도가 느렸습니다. CPU나 메모리 사용도 여유로웠고 VDI 밖에서 네트워크도 준수한 속도를 가지고 있었습니다.\n검색을 해보니 3D 가속에 이슈가 있어보이고 옵션을 끄는 방식으로 해결이 가능합니다.\n방법 1 - VMware에서 Accelerate 3D Graphics 끄기 VM이 꺼진 상태에서 Virtual Machine \u003e Settings \u003e Display 메뉴로 이동 후 Accelerate 3D Graphics 체크를 해지 합니다.","방법-2---directx-sdk-설치-후-software-only로-변경#방법 2 - DirectX SDK 설치 후 software only로 변경":" DirectX SDK를 설치 Windows에서 DirectX SDK를 설치합니다.\n다운로드 경로 : https://www.microsoft.com/ko-kr/download/details.aspx?id=6812\nDirectX Control Panel 설정변경 DirextX Control Panel을 실행한 뒤 Direct3D 9 탭에서 Software Only를 체크합니다.","상황#상황":"","현재-환경#현재 환경":""},"title":"[VMware] Ctrix workspace 느린현상"},"/blog/20240113-logioptions/":{"data":{"":"","해결방법-1---offline-설치#해결방법 1 - offline 설치":"","해결방법-2-----no-sandbox-옵션#해결방법 2 - \u0026ndash;no-sandbox 옵션":"현상 프록시가 있는 사내 환경에서 Logi Options+를 설치하고 사용하려고 했습니다. 그런데 설치가 잘 안되거나 실행이 안되는 현상이 있어 해결한 방법을 공유합니다.\n해결방법 1 - offline 설치 기본 설치파일은 온라인을 경유하여 다운로드를 받게 됩니다. 따라서 프록시나 인터넷이 안되는 환경에서는 다음 오프라인 버전을 사용합니다.\nhttps://prosupport.logi.com/hc/en-us/articles/10991109278871-Logitech-Options-Offline-Installer\n내용 중간의 Windows Options+ Offline Version 또는 Mac Options+ Offline Version을 선택하여 받으면 됩니다.\n해결방법 2 - –no-sandbox 옵션 설치까지 완료하였는데 실행에서 문제가 있을 수 있습니다. 현상은 보통 실행시켰는데 화면이 나오지 않고 아무 반응이 없습니다.\n설치된 경로 (보통 C:\\Program Files\\LogiOptionsPlus)에 보면 debug.log 파일이 있고 내용을 보면 다음과 같을 것 입니다.\nFailed to load C:\\Program Files\\LogiOptionsPlus\\chrome_100_percent.pak Some features may not be available. 일부 기능로딩에 문제가 있고 임시방편으로 sandbox 모드를 해제하는 것 입니다. 아래와 같이 명령 끝에 --no-sandbox를 추가하여 실행하면 정상실행됩니다.\nC:\\Program Files\\LogiOptionsPlus\u003e logioptionsplus.exe --no-sandbox 다만 보안적 요소와 관련된 설정이므로, 필요한 설정을 마친 뒤 프로세스를 꼭 종료해야합니다.","현상#현상":""},"title":"[LogiOptions+] 실행안됨현상 해결"},"/boto3/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\nAWS SDK for Python (Boto3)를 활용해서 아마존 엘라스틱 컴퓨터 클라우드 (Amazon EC2)와 아마존 단순 저장소 서비스 (Amazon S3) 등과 같은 AWS 서비스를 생성하고 구성하고 관리할 수 있습니다. SDK는 AWS 서비스의 저수준 접근까지 가능하도록 객체지향 API를 제공합니다..\nℹ️ 문서와 개발자들은 AWS SDK for Python을 Boto3로 언급하는 경우가 많으며 이 문서 또한 그렇습니다. "},"title":"Boto3"},"/boto3/example/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/examples.html\n이번 절은 AWS SDK for Python을 사용해서 어떻게 다양한 AWS 서비스를 호출하는지 보여주는 코드 예제를 소개합니다. 예제와 추가적인 예제 프로그램에 대한 소스코드는 AWS Code Catalog에 있습니다."},"title":"코드 예제"},"/boto3/example/s3/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-examples.html\n아마존 단순 스토리지 서비스 (Amazon S3)는 확장성, 데이터 유효성, 보안, 성능을 제공하는 객체 스토리지 서비스 입니다.\n이번 절은 AWS SDK for Python을 사용해서 어떻게 Amazon S3 서비스에 접근하는지 보여줍니다.","예제#예제":" Amazon S3 버킷 파일 업로드 파일 다운로드 파일 전송 구성 사전인증 URL 버킷 정책 접근 권한 아마존 S3 버킷을 정적웹호스트로 사용하기 버킷 CORS 구성 아마존 S3의 AWS PrivateLink "},"title":"Amazon S3 예제"},"/boto3/example/s3/access-permissions/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-access-permissions.html\n이번 절에서 접근권한목록(ACL)을 사용해서 S3 버킷이나 객체에 대한 접근권한을 어떻게 관리하는지 알아보겠습니다.","버킷-접근-권한-목록-가져오기#버킷 접근 권한 목록 가져오기":"아래 예제는 S3 버킷의 현재 접근권한목록을 검색하는 것 입니다.\nimport boto3 # 버킷의 ACL 검색하기 s3 = boto3.client('s3') result = s3.get_bucket_acl(Bucket='BUCKET_NAME') print(result) "},"title":"접근 권한"},"/boto3/example/s3/bucket-policies/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-bucket-policies.html\nS3 버킷은 다른 AWS 계정, AWS 식별자와 접근 관리(IAM) 사용자에 대한 접근권한을 부여할 수 있는 선택적 옵션을 가지고 있습니다. 버킷 정책은 자원기반 IAM 정책과 동일한 JSON 형식을 사용하여 정의할 수 있습니다.","버킷-정책-검색하기#버킷 정책 검색하기":"파이썬용 AWS SDK의 get_bucket_policy 함수를 호출하여 버킷 정책을 검색할 수 있습니다. 함수는 특정 버킷이름을 인자로 받습니다.\nimport boto3 # 특정 버킷의 정책을 검색하기 s3 = boto3.client('s3') result = s3.get_bucket_policy(Bucket='BUCKET_NAME') print(result['Policy']) ","버킷-정책-삭제하기#버킷 정책 삭제하기":"버킷 정책은 delete_bucket_policy 함수를 후출하여 삭제할 수 있습니다.\n# 버킷 정책 삭제하기 s3 = boto3.client('s3') s3.delete_bucket_policy(Bucket='BUCKET_NAME') ","버킷-정책-설정하기#버킷 정책 설정하기":"버킷 정책은 put_bucket_policy 함수를 호출하여 설정할 수 있습니다.\n정책은 IAM 정책과 동일한 JSON 형식으로 정의됩니다. 아래 예제에서 정의된 정책은 사용자가 bucket_name 변수로 식별된 버킷에 저장되어있는 객체를 검색할 수 있도록 활성화 하는 것 입니다.\nimport json import boto3 # 버킷 정책 생성하기 bucket_name = 'BUCKET_NAME' bucket_policy = { 'Version': '2022-01-01', 'Statement': [{ 'Sid': 'AddPerm', 'Effect': 'Allow', 'Principal': '*', 'Action': ['s3:GetObject'], 'Resource': f'arn:aws:s3:::{bucket_name}/*' }] } # 정책을 JSON 딕셔너리에서 문자열로 전환하기 bucket_policy = json.dumps(bucket_policy) # 새로운 정책 설정하기 s3 = boto3.client('s3') s3.put_bucket_policy(Bucket_name=bucket_name, Policy=bucket_policy) "},"title":"버킷 정책"},"/boto3/example/s3/configuring-buckets/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-configuring-buckets.html\n교차 출처 자원 공유(Cross Origin Resource Sharing, CORS)는 하나의 도메인 클라이언트 웹 어플리케이션에서 다른 도메인의 자원에 접근가능하도록 합니다. 구성은 허용할 출처, HTTP 방법(GET, PUT, 등), 다른 요소를 정의하는 규칙을 선언합니다.","버킷-cors-구성-검색하기#버킷 CORS 구성 검색하기":"파이썬용 AWS SDK의 get_bucket_cors 함수를 호출하여 버킷의 CORS 구성을 검색할 수 있습니다.\nimport logging import boto3 from botocore.exceptions import ClientError def get_bucket_cors(bucket_name): \"\"\" 아마존 S3 버킷의 CORS 구성 규칙을 검색하기 :param bucket_name: 문자열 :return: 버킷의 CORS 구성 규칙 목록. CORS 구성이 없다면 공백 목록 반환. 오류 발생시 None 반환 \"\"\" # CORS 구성 검색하기 s3 = boto3.client('s3') try: response = s3.get_bucket_cors(Bucket=bucket_name) except ClientError as e: if e.response['Error']['Code'] == 'NoSuchCORSConfiguration': return [] else: # AllAccessDisabled 오류 == 버킷을 찾을 수 없음 logging.error(e) return None; return response['CORSRules'] ","버킷-cors-구성-설정하기#버킷 CORS 구성 설정하기":"put_bucket_cors 함수를 호출하여 버킷의 CORS 구성을 설정할 수 있다.\n# 구성 규칙 정의하기 cors_configuration = { 'CORSRules': [{ 'AllowedHeaders': ['Authorization'], 'AllowedMethods': ['GET', 'PUT'], 'AllowedOrigins': ['*'], 'ExposeHeaders': ['ETag', 'x-amz-request-id'], 'MaxAgeSeconds': 3000 }] } # CORS 구성 설정하기 s3 = boto3.client('s3') s3.put_bucket_cors(Bucket='BUCKET_NAME', CORSConfiguration=cors_configuration) "},"title":"버킷 CORS 구성"},"/boto3/example/s3/creating-buckets/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-creating-buckets.html\nAmazon S3 버킷은 파일을 보관하는 저장소 위치입니다. S3 파일들은 객체를 참조하고 있습니다.\n이번 절에서는 S3 버킷관련 일반적인 동작을 어떻게 수행하는지 파이썬용 AWS SDK 사용하는 방법을 알아보겠습니다.","amazon-s3-버킷-만들기#Amazon S3 버킷 만들기":"Amazon S3 버킷의 이름은 AWS 플랫폼의 모든 지역에서 유일해야합니다. 버킷은 지연을 최소화 하거나 규제요구사항을 해결하기 위해 특정 지역에 위치할 수 있습니다.\nimport logging import boto3 from botocore.exceptions import ClientError def create_bucket(bucket_name, region=None): \"\"\" 특정 지역에 S3 버킷을 생성하기 리전이 지정되어있지 않으면, 버킷은 S3 기본 리전(us-east-1)에 생성됩니다. :param bucket_name: 생성할 버킷 이름 :param region: 생성될 버킷의 지역 문자열, 예: us-west-2 :return: 버킷이 생성되면 True, 아니면 False \"\"\" # 버킷생성하기 try: if region is None: s3_client = boto3.client('s3') s3_client.create_bucket(Bucket=bucket_name) else: s3_client = boto3.client('s3', region_name=region) location = {'LocationConstraint': region} s3_client.create_bucket(Bucket=bucket_name, CreaetBucketConfiguration=location) except ClientError as e: logging.error(e) return False return True ","기존-버킷-목록조회#기존 버킷 목록조회":"AWS 계정에 있는 기존 버킷 목록을 조회하는 것 입니다.\n# 기존 버킷목록 가져오기 s3 = boto3.client('s3') resposne = s3.list_buckets() # 버킷이름 출력하기 print('Existing buckets:') for bucket in response['Buckets']: print(f' {bucket[\"Name\"]}') "},"title":"Bucket 생성"},"/boto3/example/s3/download-file/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html\n파이썬용 AWS SDK가 제공하는 파일 다운로드 함수는 파일 업로드와 비슷합니다.\ndownload_file 함수는 버킷의 이름과 다운로드할 객체, 파일이 저장될 파일이름을 인자로 받습니다.\nimport boto3 s3 = boto3.client('s3') s3.download_file('BUCKET_NAME', 'OBJECT_NAME', 'FILE_NAME') download_fileobj 함수는 쓰기가능한 파일같은 객체를 인자로 받습니다. 파일 객체는 텍스트모드가 아닌 바이너리 모드로 열려있어야 합니다.\ns3 = boto3.client('s3') with open('FILE_NAME', 'wb') as f: s3.download_fileobj('BUCKET_NAME', 'OBJECT_NAME', f) 업로드와 비슷하게, 다운로드 함수도 S3 Client, Bucket, Object 클래스에서 제공되며 각각 클래스에서 제공하는 기능은 모두 동일합니다. 편한 클래스를 선택해서 사용하면 됩니다.\n또한 업로드 함수같이 다운로드 함수는 선택적 ExtraArgs와 Callback 인자를 지원합니다.\n다운로드 함수에 설정가능한 ExtraArgs 목록은 S3Transfer 객체의 ALLOWED_DOWNLOAD_ARGS 속성에 정의되어있습니다. 자세한 내용은 boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS를 참고하세요.\n다운로드 함수의 Callback 인자는 업로드 함수와 동일한 목적으로 사용됩니다. 업로드와 다운로드 함수 모두 동일한 Callback 클래스를 실행합니다."},"title":"파일 다운로드"},"/boto3/example/s3/file-transfer/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3.html\n파일이나 S3 객체를 업로드, 다운로드, 복사할 때 파이썬용 AWS SDK는 자동으로 재시도, 분할/통합 전송을 관리합니다.\n관리 동작은 대부분의 시나리오에 잘 맞도록 알맞은 기본 설정값을 사용하여 동작됩니다. 특별한 경우를 다루기 위해 기본 설정을 요구사항에 맞춰 구성할 수도 있습니다.\n구성 설정은 boto3.transfer.TransferConfig 객체에 저장됩니다. 객체는 전송 함수(upload_file, download_file 등)에서 Config= 인자로 전달되어집니다.\n남은 절에서 TransferConfig 객체를 가지고 다양한 전송 동작을 구성하는지 알아보겠습니다.","병렬전송-동작#병렬전송 동작":"병렬 S3 API 전송 동작의 최대 숫자는 접속 속도에 맞게 조정될 수 있습니다. 대역폭 사용량을 가감하기 위해 max_concurrency 속성으로 설정할 수 있습니다.\n기본 설정값은 10 입니다. 대역폭 사용량을 줄이려면 값을 줄이고 높이려면 값을 높이면 됩니다.\n# 다운스트림 대역폭을 조금만 사용하려면 최대 병렬을 감소시킵니다. config = TransferConfig(max_concurrency=5) # S3 객체를 다운로드 합니다. s3 = boto3.client('s3') s3.download_file('BUCKET_NAME', 'OBJECT_NAME', 'FILE_NAME', Config=config) ","분할전송#분할전송":"분할전송은 파일크기가 multipart_threshold 속성의 값을 초과했을때 동작합니다.\n아래 예제에서 TransferConfig 객체에 정의된 한계값보다 파일의 크기가 클경우 분할로 전송되도록 upload_file을 구성하였습니다.\nimport boto3 from boto3.s3.transfer import TransferConfig # 원하는 분할 한계값 설정하기 (5GB) GB = 1024 ** 3 config = TransferConfig(multipart_threshold=5 * GB) # 전송 수행하기 s3 = boto3.client('s3') s3.upload_file('FILE_NAME', 'BUCKET_NAME', 'OBJECT_NAME', Config=config) ","쓰레드#쓰레드":"전송동작은 병렬을 구현하기 위해 쓰레드를 사용합니다. use_threads 속성을 False로 설정하여 쓰레드사용을 비활성화 할 수 있습니다.\n쓰레드사용이 비활성화되면, 병렬 전송은 발생되지 않습니다. 따라서, max_concurrency 속성의 값이 무시됩니다.\n# 쓰레드 사용/병렬 전송 비활성화 config = TransferConfig(use_threads=False) s3 = boto3.client('s3') s3.download_file('BUCKET_NAME', 'OBJECT_NAME', 'FILE_NAME', Config=config) "},"title":"파일 전송 구성"},"/boto3/example/s3/presigned-urls/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-presigned-urls.html\nAWS 인증 또는 S3 객체에 접근할 권한이 없는 사용자에게 사전인증 URL을 사용하여 임시적 접근을 부여할 수 있습니다.\n사전인증 URL은 객체에 접근할 수 있는 AWS 사용자가 생성할 수 있습니다. 생성된 URL은 미인증 사용자에게 전달될 수 있습니다. 사전인증 URL은 브라우저에서 접근가능하거나 프로그램 또는 HTML 웹페이지에서 사용될 수 있습니다. 사전인증 URL에 사용되는 인증정보는 이 URL을 생성한 AWS 사용자의 정보입니다.\n사전인증 URL은 URL이 생성될 때 정의되는 제한된 기간의 시간동안만 유효하게 됩니다.\nimport logging import boto3 from botocore.exceptions import ClientError def create_presigned_url(bucket_name, object_name, expiration=3600): \"\"\"S3 객체를 공유하기 위해 사전인증 URL 생성하기 :param bucket_name: string :param object_name: string :param expiration: 사전인증 URL이 유효한 시간(초) :return: 문자열의 사전인증URL. 오류가 있으면 None 반환 \"\"\" # S3 객체를 위한 사전인증 URL을 생성한다. s3_client = boto3.client('s3') try: response = s3_client.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': object_name}, ExpiresIn=expiration) except ClientError as e: logging.error(e) return None # 사전인증 URL이 포함된 응답 return resposne 브라우저에서 사전인증 URL을 입력하여 S3 객체를 다운로드할 수 있습니다. 프로그램 또는 HTML 페이지는 HTTP GET 요청으로 사전인증 URL을 사용하여 S3 객체를 다운받을 수 있습니다.\n아래 코드는 파이썬 requests 패키지를 사용하여 GET 요청을 수행하는 것을 보여줍니다.\nimport requests # 설치하기: pip install requests url = create_presigned_url('BUCKET_NAME', 'OBJECT_NAME') if url is not None: response = requests.get(url) ","다른-s3-동작을-수행하기-위한-사전인증-url-사용하기#다른 S3 동작을 수행하기 위한 사전인증 URL 사용하기":"사전인증 URL의 주 목적은 S3 객체에 사용자 임시 접근을 부여하는 것 입니다. 그러나, 사전인증 URL은 S3 버킷과 객체에 대한 추가적인 동작을 수행할 수 있도록 권한을 부여하는데 사용될 수 있습니다.\n아래에 보여주는 create_presigned_url_expanded 함수는 특정 S3 동작을 수행하기 위한 사전인증 URL을 생성하는 것 입니다. 함수는 ’list_buckets’나 ‘get_bucket_location’와 같은 S3 client 함수의 이름을 인자로 받습니다. 함수에 전달되는 파라미터는 method_parameters 딕셔너리 인자에 정의되어있습니다. 사용할 HTTP 방식(GET, PUT 등)은 정의 가능하나 파이썬용 AWS SDK에서 적절한 방식을 선택하기 때문에 이 인자는 필수는 아닙니다.\nimport logging import boto3 from botocore.exceptions import ClientError def create_presigned_url_expanded(client_method_name, method_parameters=None, expiration=3600, http_method=None): \"\"\" S3.Client 함수를 실행하기 위한 사전인증 URL 생성하기 AWS 파이썬 SDK에서 제공하는 모든 클라이언트 함수가 지원되지는 않습니다. :param client_method_name: S3.Client 함수의 이름. 예, 'list_buckets' :param method_parameters: 함수에 전달할 파라미터 딕셔너리 :param expiration: 사전인증 URL이 유효한 시간 :param http_method: 사용할 HTTP 방식 (GET 등) :return: 사전인증 URL 문자열. 오류시 None 반환 \"\"\" # S3 클라이언트 함수를 위한 사전인증 URL 생성하기 s3_client = boto3.client('s3') try: response = s3_client.generate_presigned_url(ClientMethod=client_method_name, Params=method_parameters, ExpiresIn=expiration, HttpMethod=http_method) except ClientError as e: logging.error(e) return None # 사전인증 URL을 포함한 응답 return response ","파일업로드를-위한-사전인증-url-생성하기#파일업로드를 위한 사전인증 URL 생성하기":"파일을 업로드하기위한 AWS 인증정보를 가지고 있지 않은 사용자도 사전인증 URL을 통해 업로드를 수행할 수 있습니다. 업로드 동작은 HTTP POST 요청을 만들고 요청의 일부분으로 전송될 추가적인 인자를 필요로 합니다.\nimport logging import boto3 from botocore.exceptions import ClientError def create_presigned_post(bucket_name, object_name, fields=None, conditions=None, expiration=3600): \"\"\" 파일을 업로드하기 위한 사전인증 URL S3 POST 요청 생성하기 :param bucket_name: 문자열 :param object_name: 문자열 :param fields: 미리채워진 양식필드 딕셔너리 :param conditions: 정책에 포함할 조건 목록 :param expiration: 사전인증 URL이 유효한 시간(초) :return: 아래의 키를 가진 딕셔너리 url: POST 요청 URL fields: POST와 함께 제출될 양식 항목과 값의 딕셔너리 :return : 오류시 None \"\"\" # 사전인증 S3 POST URL 생성하기 s3_client = boto3.client('s3') try: response = s3_client.generate_presigned_post(bucket_name, object_name, Fields=fields, Conditions=conditions, ExpiresIn=expiration) except ClientError as e: logging.error(e) return None # 사전인증 URL과 요구되는 항목을 포함한 응답 return response 생성된 사전인증 URL은 후속으로 진행할 HTTP POST 요청에 전달될 URL과 추가적인 항목을 포함하고 있습니다.\n아래 코드는 파일을 S3에 업로드하기위해 requests 패키지를 사용하여 사전인증 POST URL로 POST 요청을 수행하는 것을 보여줍니다.\nimport requests # 설치필요시 : pip install requests # 사전인증 URL 생성하기 object_name = 'OBJECT_NAME' response = create_presigned_post('BUCKET_NAME', object_name) if response is None: exit(1) # 다른 파이썬 프로그램에서 파일을 업로드하기 위해 사전인증 URL을 어떻게 사용하는지 보여줍니다. with open(object_name, 'rb') as f: files = {'file': (object_name, f)} http_response = requests.post(response['url'], data=response['fields'], files=files) # 성공하면 HTTP 상태코드 204가 반환됩니다. logging.info(f'파일 업로드 HTTP 상태코드: {http_response.status_code}') 사전인증 URL과 항목은 HTML 페이지에서도 사용될 수 있습니다.\n\u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003c!-- S3Client.generate_presigned_post() 에서 반환된 'url' 값 복사--\u003e \u003cform action=\"URL_VALUE\" method=\"post\" enctype=\"multipart/form-data\"\u003e \u003c!-- S3Client.generate_presigned_post() 에서 반환된 키/값형식의 'fields' 복--\u003e \u003cinput type=\"hidden\" name=\"key\" value=\"VALUE\" /\u003e \u003cinput type=\"hidden\" name=\"AWSAccessKeyId\" value=\"VALUE\" /\u003e \u003cinput type=\"hidden\" name=\"policy\" value=\"VALUE\" /\u003e \u003cinput type=\"hidden\" name=\"signature\" value=\"VALUE\" /\u003e File: \u003cinput type=\"file\" name=\"file\" /\u003e \u003cbr /\u003e \u003cinput type=\"submit\" name=\"submit\" value=\"Upload to Amazon S3\" /\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e "},"title":"사전인증 URL"},"/boto3/example/s3/privatelink/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-privatelink.html\n이번 절에서 인터페이스 VPC 접점를 사용하기 위해 S3 클라이언트를 구성하는 방법을 보여주겠습니다.","클라이언트-접점-url-구성하기#클라이언트 접점 URL 구성하기":"인터페이스 VPC 접점을 사용하기 위해 S3 클라이언트를 구성할 때, 클라이언트에서 사용되는 접점에 명시할 자원의 유형은 하나만 참조될 수 있습니다. 버킷과 접근 지점에 둘다 접근하려면 각각 자원 유형을 위한 두개의 클라이언트를 인스턴화 해야합니다.\n아래 예제는 인터페이스 VPC 접점을 통해 S3 버킷에 접속할 수 있도록 S3 클라이언트를 구성하는 것 입니다.\nimport boto3 s3_client = boto3.client( service_name='s3', endpoint_url='https://bucket.vpce-abc123-abcdefgh.s3.us-east-1.vpce.amazonaws.com' ) 아래 예제는 인터페이스 VPC 접점을 통해 S3 접근 지점에 접속할 수 있도록 S3 클라이언트를 구성하는 것입니다. 이 클라이언트는 S3 버킷을 참조할 때 사용될 수 없습니다.\nimport boto3 s3_client = boto3.client( service_name='s3', endpoint_url='https://accesspoint.vpce-abc123-abcdefgh.s3.us-east-1.vpce.amazonaws.com' ) 아래 예제는 인터페이스 VPC 접점을 사용하기 위해 S3 제어 클라이언트를 구성하는 것 입니다.\nimport boto3 control_client = boto3.client( service_name='s3control', endpoint_url='https://control.vpce-abc123-abcdefgh.s3.us-east-1.vpce.amazonaws.com' ) "},"title":"PrivateLink"},"/boto3/example/s3/static-web-host/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-static-web-host.html\nS3 버킷으로 정적웹사이트 호스팅을 구성할 수 있습니다.","웹사이트-구성-검색하기#웹사이트 구성 검색하기":"파이썬용 AWS SDK의 get_bucket_website 함수를 호출하여 버킷의 웹사이트 구성을 검색할 수 있습니다.\nimport boto3 # 웹사이트 구성 검색하기 s3 = boto3.client('s3') result = s3.get_bucket_website(Bucket='BUCKET_NAME') ","웹사이트-구성-삭제하기#웹사이트 구성 삭제하기":"delete_bucket_website 함수 호출해서 버킷의 웹사이트 구성을 삭제할 수 있습니다.\n# 웹사이트 구성 삭제하기 s3 = boto3.client('s3') s3.delete_bucket_website(Bucket='BUCKET_NAME') ","웹사이트-구성-설정하기#웹사이트 구성 설정하기":"put_bucket_website 함수를 호출해서 버킷의 웹사이트 구성을 설정할 수 있습니다.\n# 웹사이트 구성 정의하기 website_configuration = { 'ErrorDocument': {'Key': 'error.html'}, 'IndexDocument': {'Suffix': 'index.html'}, } # 웹사이트 구성 설정하기 s3 = boto3.client('s3') s3.put_bucket_website(Bucket='BUCKET_NAME', WebsiteConfiguration=website_configuration) "},"title":"정적 웹호스트"},"/boto3/example/s3/uploading-files/":{"data":{"":" https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html\n파이썬용 AWS SDK는 S3 버킷에 파일을 업로드하는 두가지 함수를 제공합니다.\nupload_file 함수는 파일이름, 버킷이름, 객체이름을 인자로 받습니다. 함수는 작은 청크로 분할하고 병렬로 청크를 업로드하여 큰파일을 다룹니다.\nimport logging import boto3 from botocore.exceptions import ClientError import os def upload_file(file_name, bucket, object_name=None): \"\"\" S3 버킷에 파일을 업로드합니다. :param file_name: 업로드할 파일 :param bucket: 업로드될 버킷 :param object_name: S3 객체이름. 없으면 file_name 사용 :return: 파일이 업로드되면 True, 아니면 False \"\"\" # S3 객체이름이 정의되지 않으면, file_name을 사용 if object_name is None: object_name = os.path.basename(file_name) # 파일 업로드 s3_client = boto3.client('s3') try: resposne = s3_client.upload_file(file_name, bucket, object_name) except ClientError as e: logging.error(e) return False return True upload_fileobj 함수는 읽기가능한 파일같은 객체를 허용합니다. 파일객체는 텍스트모드가 아닌 바이너리 모드로 열려있어야 합니다.\ns3 = boto3.client('s3') with open(\"FILE_NAME\", \"rb\") as f: s3.upload_fileobj(f, \"BUCKET_NAME\", \"OBJECT_NAME\") upload_file과 upload_fileobj 함수는 S3의 Client, Bucket, Object 클래스에서 모두 제공합니다. 각각의 클래스에서 제공하는 함수의 기능은 모두 동일합니다. 한 클래스의 함수를 다른 클래스에서 호출하는 것에 대한 이점은 없습니다. 어떤 클래스던 편리한 것을 사용하세요.","callback-파라미터#Callback 파라미터":"upload_file과 upload_fileobj는 선택적으로 Callback 파라미터를 받습니다. 이 파라미터는 파이썬 SDK가 전송동작중 간헐적으로 호출되는 클래스를 참조합니다.\n호출되는 파이썬 클래스는 __call__ 함수를 실행합니다. 각각의 호출에서 클래스는 그 시점에 전송된 바이트수를 전달받을 수 있습니다. 이 정보는 진행률 모니터를 구현하는데 사용될 수 있습니다.\n아래 Callback 설정은 파이썬 SDK가 ProgressPercentage 클래스의 인스턴스를 생성하는 동작입니다. 업로드 중에 인스턴스의 __call__ 함수가 간헐적으로 호출되어집니다.\ns3.upload_file( 'FILE_NAME', 'BUCKET_NAME', 'OBJECT_NAME', Callback=ProgressPercentage('FILE_NAME') ) ProgressPercentage 클래스의 예제구현은 아래와 같습니다.\nimport os import sys import threading class ProgressPercentage(object): def __init__(self, filename): self._filename = filename self._size = float(os.path.getsize(filename)) self._seen_so_far = 0 self._lock = threading.lock() def __call__(self, bytes_amount): # 단순하게 단일 파일을 처리한다고 가정하자 with self._lock: self._seen_so_far += bytes_amount percentage = (self._seen_so_far / self.size) * 100 sys.stdout.write( \"\\r%s %s / %s (%.2f%%)\" % ( self._filename, self._seen_so_far, self._size, percentage)) sys.stdout.flush() ","extraargs-파라미터#ExtraArgs 파라미터":"upload_file과 upload_fileobj는 다양한 목적으로 사용되는 ExtraArgs 파라미터를 받습니다. ExtraArgs에 가능한 셋팅목록은 S3Transfer 객체의 ALLOWED_UPLOAD_ARGS 속성에 정의되어있습니다. boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS를 참고하세요.\n아래의 ExtraArgs 설정은 S3 객체에 붙일 메타데이터를 정의한 것입니다.\ns3.upload_file( 'FILE_NAME', 'BUCKET_NAME', 'OBJECT_NAME', ExtraArgs={'ACL': 'public-read'} ) 아래의 ExtraArgs 설정은 S3 객체에 ‘public-read’라는 고정된 ACL(접근 제어 목록, access control list)을 정의하는 것 입니다.\ns3.upload_file( 'FILE_NAME', 'BUCKET_NAME', 'OBJECT_NAME', ExtraArgs={'ACL': 'public-read'} ) 또한, ExtraArgs에 사용자정이 또는 다수의 ACL을 설정할 수 있습니다.\ns3.upload_file( 'FILE_NAME', 'BUCKET_NAME', 'OBJECT_NAME\", ExtraArgs={ 'GrantRead': 'uri=\"http://acs.amazonaws.com/groups/global/AllUsers\"', 'GrantFullControl': 'id=\"01234567890abcdefg\"' } ) "},"title":"파일 업로드"},"/docs/":{"data":{"":" Elasticsearch 구성하기 Elasticsearch 문서 Boto3 문서 UML 튜토리얼 "},"title":"문서번역"},"/elastic/":{"data":{"":"Elasticsearch 관련 문서 번역입니다."},"title":"Elasticsearch"},"/elastic/rest-apis/":{"data":{"":"엘라스틱서치는 UI 컴포넌트에서 사용하거나 직접 호출하여 엘라스틱서치의 기능을 구성하고 접근할 수 있는 REST API를 제공합니다.\n이번 절에서 대부분의 엘라스틱서치 API를 포함하려고 작업하고 있습니다. 몇몇 내용은 아직 포함되어있지 않을 수 있습니다."},"title":"REST API"},"/elastic/rest-apis/indices-split-index/":{"data":{"":"","split-index-api-desc#설명":"","split-index-api-path-params#경로 매개변수":"","split-index-api-prereqs#사전조건":"","split-index-api-query-params#쿼리 매개변수":"","split-index-api-request#요청":"","split-index-api-request-body#요청 본문":" https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-split-index.html\n기존 인덱스를 추가적인 기본 샤드를 가진 새로운 인덱스로 분할합니다.\nPOST /my-index-000001/_split/split-my-index-000001 { \"settings\": { \"index.number_of_shards\": 2 } } def test(self, aaa: int) -\u003e None: pass 요청 POST /\u003cindex\u003e/_split/\u003ctarget-index\u003e\nPUT /\u003cindex\u003e/_split/\u003ctarget-index\u003e\n사전조건 만약 엘라스틱서치의 보안기능이 활성화되어있다면, 작업할 인덱스에 대한 manage 권한이 있어야 합니다. 인덱스를 분할하기 전에 인덱스는 읽기 전용이어야 합니다. 클러스터의 상태는 그린이어야 합니다. 아래의 요청으로 인덱스를 읽기전용으로 만들 수 있습니다.\nPUT /my_source_index/_settings { \"settings\": { \"index.blocks.write\": true } } 인덱스에 쓰기 동작을 방지하더라도 인덱스 삭제와 같은 메타데이터 변경은 허용됩니다. 현재 데이터 스트림에서 쓰고있는 인덱스는 분할할 수 없습니다. 현재 쓰고 있는 인덱스를 분할하기 위해서는 데이터 스트림이 먼저 롤오버되어 새로운 인덱스에 쓰기를 해야 이전 인덱스의 분할이 가능합니다.\n설명 분할 인덱스 API는 기존 인덱스의 기본 샤드를 두개 또는 그이상으로 분할하여 새로운 인덱스를 만들 수 있게 합니다.\n인덱스를 분할할 수 있는 횟수(원래 샤드가 분할하여 변경되는 샤드 수)는 index.number_of_routing_shards 설정으로 결정됩니다. 라우팅 샤드의 수는 일관된 해싱으로 문서를 내부적으로 분산하도록 하는 해싱 공간을 정의합니다. 예로, 5개 샤드를 가진 인덱스가 number_of_routing_shards를 30 (5 x 2 x 3)으로 설정하면 2 또는 3의 배수로 나뉘게 됩니다. 다시 설명하면 아래와 같이 분산됩니다.\n5 \u003e 10 \u003e 30 (2로 분할 후 3으로 분할) 5 \u003e 15 \u003e 30 (3으로 분할 후 2로 분할) 5 \u003e 30 (6으로 분할) index.number_of_routing_shards는 정적 인덱스 설정 입니다. 따라서 index.number_of_routing_shards의 설정은 인덱스 생성 시점 또는 종료된 인덱스에서 가능합니다.\n인덱스 생성 예제 아래의 [인덱스 생성 API]는 my-index-000001 인덱스를 index.number_of_routing_shards를 30으로 설정하여 생성하는 것 입니다.\nPUT /my-index-000001 { \"settings\": { \"index\": { \"number_of_routing_shards\": 30 } } } index.number_of_routing_shards 설정의 기본값은 원본 인덱스의 기본 샤드의 개수에 종속됩니다. 기본값은 최대 1024의 샤드를 2배수로 분할할 수 있도록 고안되어있습니다. 그러나, 기본 샤드의 원래 개수를 고려해야 합니다. 예로 들면, 5개의 기본샤드로 생성된 인덱스는 10, 20, 40, 80, 160, 320 또는 최대 640 샤드로 분할(단일 분할 또는 다중 분할) 될 수 있습니다.\n만약 원래 인덱스가 한개의 샤드 (또는 다중-샤드 인덱스에서 단일 기본샤드로 축소된 것)를 가지고 있는 경우, 1보다 큰 임의의 샤드 수로 분할될 수 있습니다. 라우팅 샤드의 기본값 속성은 새로 분할된 인덱스에 적용이 가능합니다.\n분할 동작 원리 분할 동작은 다음과 같습니다.\n대상인덱스와 동일한 정의를 가지지만 더 큰수의 기본 샤드를 설정할 수 있는 새로운 인덱스를 생성합니다. 대상인덱스에서 신규인덱스로 세그먼트를 하드링크합니다. (만약 파일 시스템이 하드링크를 지원하지 않으면 처리하는데 시간이 좀더 걸리지만 새로운 인덱스로 모든 세그먼트를 복사합니다) 하위 수준의 파일이 생성되면 다른 샤드에 속해있는 문서를 삭제하기 위해 모든 문서를 다시 해싱합니다. 다시 오픈할 닫힌 인덱스처럼 신규 인덱스를 복구합니다. 왜 엘라스틱서치가 증분 재샤딩을 지원하지 않을까? N 샤드에서 N+1 샤드로 확장되는, 일명 증분 재샤딩은 많은 키-값 저장소에서 지원되는 기능입니다. 새로운 샤드를 추가하고 새로운 데이터를 이 샤드로 저장하는 것은 선택지가 아닙니다. 이런 환경에서는 인덱싱 병목이 발생하고 조회/삭제/갱신 요청에 필요한 주어진 _id를 가지고 문서가 어떤 샤드에 속해있는지 알아내는 것이 더 복잡해집니다. 따라서 다른 해싱 스키마를 가지고 기존 데이터를 재분배가 필요하다는 것 입니다.\n키-값 저장소에서 이것을 효율적으로 하기 위해 일반적으로 사용되는 방법은 일관된 해싱을 사용하는 것 입니다. 일반된 해싱은 샤드의 수를 N에서 N+1로 증가시킬 때 재할당을 위해 1/N 번째의 키만 있으면 됩니다. 그렇지만 엘라스틱서치의 저장 단위인 샤드는 루씬 인덱스 입니다. 검색기반의 데이터 구조이기 때문에 문서의 5%에 불과하더라도 루씬 인덱스의 상당부분을 차지하고 이를 삭제하고 다른 샤드에 인덱싱하는 것은 보통 키-값 저장소보다 훨씬 더 높은 비용이 발생합니다. 위 절에서 설명한 대로 샤드 수를 늘릴 때 이 비용은 곱셈 요소기반 합리적으로 유지됩니다. 이를 통해 엘라스틱서치는 분할을 로컬로 수행할 수 있으며 결과적으로 이동이 필요한 문서를 다시 색인화하는 대신 인덱스 수준에서 분할을 수행할 수 있을 뿐 아니라 효과적인 파일 복사를 위해 하드링크를 사용할 수 있습니다.\n추가만 되는 데이터의 경우, 좀더 유연하게 새로운 인덱스를 생성하고 데이터를 저장합니다. 그리고 과거와 신규 데이터에 대한 읽기 연산수행을 위하여 별칠을 추가하는 것 입니다. 과거와 신규 인덱스가 각기 M과 N 샤드를 가지고 있을 경우 M+N 샤드를 가지는 인덱스를 검색하는 것과 비교하여 오버헤드가 없습니다.\n인덱스 분할 my_source_indes를 새로운 my_target_index로 분할 하는 경우 아래와 같이 요청합니다.\nPOST /my_source_index/_split/my_target_index { \"settings\": { \"index.number_of_shards\": 2 } } 위 요청은 타겟 인덱스가 클러스터에 추가된 즉시 결과를 반환하며 분할 동작이 시작하는 것을 기다리지는 않습니다.\n⚠️ 인덱스는 아래의 요건이 모두 만족하면 분할동작을 시작합니다.\n타겟 인덱스가 존재하지 않습니다. 소스 인덱스는 타겟 인덱스보다 적은 기본 샤드를 가집니다. 타겟 인덱스의 기본 샤드수는 소스 인덱스의 기본 샤드수의 배수가 되어야합니다. 분할 동작을 처리하는 노드는 기존 인덱스의 복제본을 만들기 위해 충분한 디스크 공간이 있어야 합니다. _split API는 인덱스 생성 API와 유사하며 타겟 인덱스의 settings와 aliases 매개변수를 받습니다.\nPOST /my_source_index/_split/my_target_index { \"settings\": { \"index.number_of_shards\": 5 }, \"aliases\": { \"my_search_indices\": {} } } 분할처리 모니터링 분할 처리는 _cat 복구 API를 사용하여 모니터링하거나 cluster 상태 API를 가지고 wait_for_status 매개변수를 yellow로 설정하여 모든 기본 샤드가 할당될 때까지 대기할 수 있습니다.\n_split API는 어떤 샤드든 할당되기 전에 대상 인덱스가 클러스터 상태에 추가되면 바로 결과를 반환합니다. 이 시점에는 모든 샤드가 unassigned 상태에 있습니다. 다른 이유로 대상 인덱스가 할당되지 않으면, 기본 샤드는 해당 노드에 할당될 수 있을 때까지 unassigned로 남아있습니다.\n기본 샤드가 할당되면 상태는 initializing 상태로 전환되며 분할 처리가 시작됩니다. 분할 동작이 완료되면 샤드는 active 상태가 됩니다. 이때부터 엘라스틱서치는 복제본 할당을 시작하고 기본 샤드를 다른 노드에 재배치를 고려하게 됩니다.\n활성 샤드 대기 분할 동작은 샤드를 분할하기 위해 새로운 인덱스를 생성하기 때문에 인덱스 생성의 샤드 활성 대기 설정이 인덱스 분할 동작에도 적용 가능합니다.\n경로 매개변수 \u003cindex\u003e (필수, 문자열) 분할하고자 하는 소스 인덱스명\n\u003ctarget-index\u003e (필수, 문자열) 생성할 대상 인덱스명\n인덱스명은 아래 규칙을 따라야 합니다.\n소문자만 가능 \\, /, *, ?, \", \u003c, \u003e, |, (공백), ,, # 불가 7.0 이전버전은 콜론(:)이 가능하나 7.0 이상은 더이상 사용되지 않아 지원되지 않음 -, _, +로 시작하지 않음 ., ..가 될 수 없음 255 바이트가 될 수 없음 (바이트이므로 멀티바이트 문자열에서는 255글자보다 빨리 초과됨을 참고) 숨김 인덱스와 플러그인에서 관리하는 내부 인덱스를 제외하고 .로 시작하는 이름은 더이상 사용되지 않음 쿼리 매개변수 wait_for_active_shards (선택, 문자열) 작업을 처리하기 전에 활성화되어야하는 샤드 복사본의 수 입니다. all 또는 인덱스의 전체 샤드 수 까지의 양의 정수로 설정합니다. (number_of_replicas+1) 기본값은 1, 기본 샤드 입니다.\n자세한 것은 활성 샤드를 참고하세요.\nmaster_timeout (선택, 시간단위) 마스터 노드에 접속대기할 시간. 타임아웃이 초과되기 전까지 응답이 없으면 요청은 실패하고 오류를 반환합니다. 기본값은 30s 입니다.\ntimeout (선택, 시간단위) 응답을 기다리는 시간. 타임아웃이 초과되기 전까지 응답이 없으면 요청은 실패하고 오류를 반환합니다. 기본값은 30s 입니다.\n요청 본문 aliases (선택, 객체의 객체) 결과 인덱스의 별칭\naliases 객체의 속성 \u003calias\u003e (필수, 객체) 키는 별칭명. 인덱스 별칭이름은 날짜 계산을 지원합니다.\n객체의 본문은 별칭의 옵션을 포함합니다. 비어있는 객체도 지원합니다.\n\u003calias\u003e의 속성 filter (선택, 쿼리 DSL 객체) 별칭이 접근할 수 있는 제한된 문서에 사용될 쿼리\nindex_routing (선택, 문자열) 인덱싱 동작을 특정 샤드로 라우팅할 때 사용되는 값. 지정되면 인덱싱 동작에는 routing 값을 덮어씁니다.\nis_hidden (선택, 부울) true 이면 별칭은 숨겨집니다. 기본값은 false 입니다. 별칭의 모든 인덱스는 동일한 is_hidden 값을 가져야합니다.\nis_write_index (선택, 부울) true 이면, 인덱스는 별칭의 쓰기 인덱스가 됩니다. 기본값은 false 입니다.\nrouting (선택, 문자열) 인덱싱과 검색 동작을 특정 샤드로 라우팅할 때 사용되는 값.\nsearch_routing (선택, 문자열) 검색 동작을 특정 샤드로 라우팅할 때 사용되는 값. 지정되면 검색 동작에는 routing 값을 덮어씁니다.\nsettings (선택, 인덱스 설정 객체) 대상 인덱스에 대한 구성 옵션. 인덱스 설정을 참고하세요."},"title":"인덱스분할 API"},"/elasticsearch_setup/":{"data":{"":" https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html\n이번 절은 엘라스틱서치를 어떻게 설정하고 실행하는지 아래를 포함하여 소개합니다.\n다운로드 설치 시작하기 구성하기 ","전용-호스트를-사용하기#전용 호스트를 사용하기":"운영계에서 전용 호스트 또는 주서비스로 엘라스틱서치를 실행하길 권장합니다.\n자동 JVM 힙 사이즈와 같은 여러가지 엘라스틱서치 기능은 호스트와 컨테이너에서 자원을 많이 사용하는 어플리케이션이라고 가정합니다.\n예로 들면, 클러스터 통계를 위해 엘라스틱서치에 메트릭비트를 실행할 수 있지만, 자원을 많이 사용하는 로그스태시 배포는 독립 호스트에 배포해야합니다.","지원하는-플랫폼#지원하는 플랫폼":"공식적으로 지원하는 운영체제와 JVM에 대한 것은 지원표에 있습니다. 엘라스틱서치는 목록화된 플랫폼에서 테스트가 되었지만 그 외의 다른 플랫폼에서도 동작할 것 입니다."},"title":"Elasticsearch 설정"},"/elasticsearch_setup/config/":{"data":{"":" https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html\n엘라스틱서치는 좋은 기본값을 가지고 아주 약간의 구성을 요구하고 있습니다. 대부분의 설정은 클러스터 설정 갱신 API를 사용하여 실행중인 클러스터를 변경할 수 있습니다.\n구성 파일은 특정 노드에 한정된 설정(node.name과 경로) 또는 클러스터에 합류하기 위해 필요한 노드 설정(cluster.name와 network.host)을 포함하고 있습니다.","구성-파일-위치#구성 파일 위치":"엘라스틱서치는 3가지 구성파일을 가지고 있습니다.\n엘라스틱서치 구성을 위한 elasitcsearch.yml 엘라스틱서치 JVM 설정의 구성을 위한 jvm.options 엘라스틱서치 로깅 구성을 위한 log4j2.properties 이 파일은 구성 디렉터리에 위치하며 기본 위치는 압축배포판(tar.gz 또는 zip) 또는 패키지배포판(데비안 또는 RPM 패키지) 설치한 방법에 따라 결정됩니다.\n압축배포판에서 구성 디렉터리 경로는 기본적으로 $ES_HOME/config입니다. 구성 디렉터리의 위치는 아래처럼 ES_PATH_CONF 환경 변수로 변경할 수 있습니다.\nES_PATH_CONF=/path/to/my/config ./bin/elasticsearch 다른 방법으로는 명령줄 또는 쉘 프로파일에 export로 ES_PATH_CONF 환경변수를 설정하는 것 입니다.\n패키지배포판에서는 구성 디렉터리 위치는 /etc/elasticsearch가 기본값입니다. 구성 디렉터리 위치는 동일하게 ES_PATH_CONF 환경변수로 변경할 수 있지만 쉘에서 설정하는 것은 아닙니다. 대신 변수는 /etc/default/elasticsearch (데비안 패키지), /etc/sysconfig/elasticsearch (RPM 패키지)에 위치해있습니다. 원하는 구성 디렉터리 위치로 변경을 위하여 이 파일에서 ES_PATH_CONF=/etc/elasticsearch 항목을 수정하면 됩니다.","구성-파일-포맷#구성 파일 포맷":"구성 포맷은 YAML 입니다. 아래는 데이터와 로그 디렉터리의 경로를 변경하는 예제입니다.\npath: data: /var/lib/elasticsearch logs: /var/log/elasticsearch 또한 설정을 단순하게 할 수 있습니다.\npath.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch YAML에서 스칼라가 아닌 값을 시퀀스로 작성할 수 있습니다.\ndiscovery.seed_hosts: - 192.168.1.10:9300 - 192.168.1.11 - seeds.mydomain.com 덜 일반적이긴 하지만, 배열형태로도 작성할 수 있습니다.\ndiscovery.seed_hosts: [\"192.168.1.10:9300\", \"192.168.1.11\", \"seeds.mydomain.com\"] ","클러스터와-노드-설정-유형#클러스터와 노드 설정 유형":"클러스터와 노드 설정은 어떻게 구성하냐에 따라 카테고리화 합니다.\n동적형 클러스터 설정 갱신 API를 사용하여 동작중인 클러스터의 동적 설정을 구성하고 갱신할 수 있습니다.\n클러스터 설정 갱신 API를 통해 업데이트한 것은 클러스터가 재시작되도 적용되는 영구적, 클러스터가 재시작되면 초기화되는 휘발성 설정이 있습니다. 또한 API를 통해 null 값을 설정해서 휘발성, 영구적 설정을 초기화할 수 있습니다.\n동일한 설정을 다양한 방법으로 구성하면 엘라스틱서치는 설정을 아래 순서대로 적용합니다.\n휘발성 설정 영구적 설정 elasticsearch.yml 설정 기본 설정 값 예로 들어, 영구적 설정 또는 elasticsearch.yml 설정을 덮어쓰기 위해 휘발성 설정을 적용할 수 있습니다. 그러나, elasticsearch.yml을 변경한 설정은 정의된 휘발성 또는 영구적 설정을 덮어쓸수 없습니다.\nℹ️ 엘라스틱서치 서비스를 사용하는 경우, 모든 클러스터 설정을 구성하기 위해 사용자 설정 기능을 사용합니다. 이 방법은 엘라스틱서치 서비스에서 클러스터를 망가뜨릴 불안정한 설정을 방지할 수 있습니다.\n자체적으로 엘라스틱서치를 실행하는 경우, 클러스터 설정갱신 API를 사용하여 동적 클러스터 설정을 구성할 수 있습니다. ’elasticsearch.yml’은 정적 클러스터 설정과 노드 설정에만 사용됩니다. API는 재시작이 필요없고 모든 노드에 동일한 설정이 있게 보장합니다.\nℹ️ 더이상 휘발성 클러스터 설정의 사용을 권장하지 않습니다. 영구적 클러스터 설정을 대신 사용하세요. 클러스터가 비정상이 되면 휘발성 설정은 예기치않게 초기화되고 궁극적으로 바람직하지 않은 클러스터 구성이 될 수 있습니다. 휘발성 설정 마이그레이션 가이드를 참고하세요. 고정형 고정형 설정은 elasticsearch.yml을 사용해서 시작안된 또는 중단된 노드에 구성할 수 있습니다.\n고정형 설정은 클러스터의 관련있는 모든 노드에 설정해야 합니다.","환경변수-대체편집#환경변수 대체편집":"구성 파일에서 환경변수는 ${...} 형식으로 참조가 가능하며 환경변수의 값으로 대체가 됩니다. 예로 들면,\nnode.name: ${HOSTNAME} network.host: ${ES_NETWORK_HOST} 환경변수의 값은 단순 문자열이어야 합니다. 쉼표로 구분된 문자열이 값으로 제공되면 엘라스틱서치에서 목록으로 파싱합니다. 예로 들어, 엘라스틱서치는 ${HOSTNAME} 환경변수의 문자열 값을 목록으로 분할합니다.\nexport HOSTNAME=\"host1,host2\" "},"title":"Elasticsearch 구성"},"/elasticsearch_setup/config/important-settings/":{"data":{"":" https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html\n엘라스틱서치는 시작하는데 아주 작은 설정을 요구하지만 운영환경에서 클러스터를 구성하는데 필수로 고려해야될 다수의 설정이 있습니다.\n경로 설정 클러스터명 설정 노드명 설정 네트워크 호스트 설정 디스커버리 설정 힙크기 설정 JVM 힙덤프 경로 설정 GC 로깅 설정 임시 디렉터리 설정 JVM 치명적 오류로그 설정 클러스터 백업 Elastic Cloud 서비스에서 이러한 설정을 자동으로 구성하며 기본적으로 운영환경에 바로 사용하 수 있도록 클러스터를 만들어줍니다.","gc-로깅-설정#GC 로깅 설정":"엘라스틱서치는 가비지컬렉션(GC) 로그를 활성화합니다. jvm.options에서 구성할 수 있고 엘라스틱서치 로그의 동일 기본경로에 출력됩니다. 기본 구성은 매 64MB 마다 로그가 순환되고 디스크공간을 최대 2GB 사용합니다.\nJEP 158: Unified JVM Logging에 설명된 것 처럼 명령줄 옵션으로 JVM 로깅을 재구성할 수 있습니다. 기본 jvm.options 파일을 직접 변경하지 않으면 엘라스틱서치는 기본 구성에 설정을 추가합니다. 기본 구성을 비활성화 하려면 -xlog:disable로 최초 로깅을 비활성화 한 뒤 명령줄 옵션을 적용합니다. 이렇게 하면 모든 JVM 로깅을 비활성화되기 때문에 사용가능한 옵션을 확인하고 필요한 모든것을 활성화 해야합니다.\nJEP 원본에 포함되지 않은 많은 옵션은 JVM Unified Logging 프레임워크로 로깅활성화를 참고하세요.\nJVM 예제 몇몇 샘플 옵션과 함께 /opt/my-app/gc.log로 기본 GC 로그 출력위치를 변경하는 $ES_HOME/config/jvm.options.d/gc.options파일 예제입니다.\n# 모든 로그설정을 비활성화 합니다. -Xlog:disable # JEP 158의 기본설정이지만 다음줄과 일치하도록 `uptime` 대신 `utctime`을 사용합니다. -Xlog:all=warning:stderr:utctime,level,tags # 다양한 옵션과 사용자정의 위치로 GC 로깅을 활성화 합니다. -Xlog:gc*,gc+age=trace,safepoint:file=/opt/my-app/gc.log:utctime,level,pid,tags:filecount=32,filesize=64m 엘라스틱서치 [Docker 컨테이너]가 GC 디버그 로그를 표준 에러(stderr)로 전송할 수 있도록 구성합니다. 이를 통해 컨테이너 오케스트레이터가 출력을 다룰 수 있습니다. ES_JAVA_OPTS 환경변수를 사용하면 다음과 같이 지정하세요.\nMY_OPTS=\"-Xlog:disable -Xlog:all=warning:stderr:utctime,level,tags -Xlog:gc=debug:stderr:utctime\" docker run -e ES_JAVA_OPTS=\"$MY_OPTS\" # etc ","jvm-치명적-오류로그-설정#JVM 치명적 오류로그 설정":"엘라스틱서치는 기본 로깅 디렉터리에 fatal 에러 로그를 작성하도록 JVM을 구성합니다. RPM과 Debian 패키지는 이 디렉터리가 /var/log/elasticsearch 입니다. 리눅스와 맥과 윈도우 배포판의 logs 디렉터리는 엘라스틱서치 설치의 상위 디렉터리에 위치합니다.\n세그먼트폴트와 같은 fatal 에러가 발생하면 JVM이 생성하는 로그가 있습니다. 로그를 받기 경로가 적절치 않다면 jvm.options의 -XX:ErrorFile=... 항목을 수정하세요.","jvm-힙덤프-경로-설정#JVM 힙덤프 경로 설정":"엘라스틱서치는 기본적으로 데이터 디렉터리에 메모리초과 오류가 발생하면 힙덤프를 받도록 JVM 설정이 되어있습니다. RPM과 Debian 패키지에서 데이터 디렉터리는 /var/lib/elasticsearch입니다. 리눅스와 맥, 윈도우 배포판은 data 디렉터리가 엘라스틱서치 설치의 상위디렉터리에 위치해있습니다.\n이 경로가 힙덤프를 받기 적절치 않으면, jvm.options의 -XX:HeapDumpPath=...를 수정합니다.\n디렉터리를 지정하면 JVM이 실행중인 인스턴스의 PID를 기반으로 힙덤프 파일명을 생성합니다. 디렉터리 대신 고정된 파일명으로 지정하면 JVM이 메모리초과 오류가 발생해서 힙덤프를 만들 때 파일이 있으면 안됩니다. 그렇지 않으면 힙덤프는 실패합니다. ","경로-설정#경로 설정":"엘라스틱서치는 인덱싱된 인덱스 데이터와 스트림 데이터를 data 디렉터리에 저장합니다. 클러스터 상태 및 동작 등의 정보를 포함한 어플리케이션 로그를 logs 디렉터리에 저장합니다.\nmacOS .tar.gz, Linux .tar.gz, Windows .zip 설치에서는 data와 logs가 $ES_HOME의 하위 디렉터리로 기본설정 되어있습니다. 그러나 $ES_HOME의 파일은 업그레이드때 삭제될 가능성이 있습니다.\n운영환경에서 elasticsearch.yml의 path.data와 path.logs를 $ES_HOME 밖으로 설정하길 권장합니다. Docker, Debian, RPM 패키지로 설치한 경우 기본적으로 $ES_HOME의 밖 위치에서 데이터와 로그를 기록합니다.\n플랫폼에 따라 path.data와 path.logs 값이 다르게 지원됩니다.\nUnix 시스템Windows 리눅스와 macOS 설치는 Unix 스타일 경로를 지원합니다.\npath: data: /var/data/elasticsearch logs: /var/log/elasticsearch Windows 설치는 이스케이프된 백슬래시와 DOS 경로를 지원합니다.\npath: data: \"C:\\\\Elastic\\\\Elasticsearch\\\\data\" logs: \"C:\\\\Elastic\\\\Elasticsearch\\\\logs\" ⚠️ 절대 데이터 디렉터리안을 수정하거나 안의 내용을 방해하는 프로세스를 실행하면 안됩니다. 엘라스틱서치가 아닌 다른 것이 데이터 디렉터리의 내용을 수정한다면, 엘라스틱서치는 오류가 발생하여 손상이나 데이터 불일치가 보고되거나 올바르게 작동하긴 하지만 일부 데이터가 손실될 수 있습니다.\n데이터 디렉터리 자체를 파일시스템 백업으로 수행하지 마세요. 대신, 스냅샷과 복구를 활용하여 안전하게 백업하세요.\n데이터 디렉터리에 바이러스 검사를 수행하지 마세요. 바이러스 검사기가 엘라스틱서치의 정상작동을 막고 데이터 디렉터리의 내용을 수정할 수 있습니다. 데이터 디렉터리에는 실행파일이 없으므로 거짓된 긍정만 발견될 수 있습니다.","네트워크-호스트-설정#네트워크 호스트 설정":"기본적으로 엘라스틱서치는 127.0.0.1 또는 [::1]과 같은 루프백 주소에만 바인딩됩니다. 이것은 개발 또는 테스트 목적으로 단일 서버에 한개이상의 노드로 클러스터를 실행할때 적합합니다. 그러나, 탄력적인 운영환경 클러스터는 다른서버의 노드를 포함해야합니다. 다양한 네트워크 설정이 있지만 보통 필요한 설정은 network.host 입니다.\nnetwork.host: 192.168.1.10 ⚠️ network.host의 값을 설정할 때 엘라스틱서치는 개발모드에서 운영모드로 전환된다고 가정하고 시스템 시작 확인의 다수를 경고에서 예외로 변경합니다. 개발과 운영 모드의 차이를 살펴보세요. ","노드명-설정#노드명 설정":"엘라스틱서치는 node.name를 사용해서 엘라스틱서치의 특정 인스턴스에 대한 사람이 읽을 수 있는 식별자 지정이 가능합니다. 이 이름은 많은 API 응답에 포함됩니다. 엘라스틱서치가 시작될 때 장치의 호스트명이 기본값으로 설정되나 명시적으로 elasticsearch.yml에 구성할 수 있습니다.\nnode.name: prod-data-2 ","다중-데이터-경로#다중 데이터 경로":" ⚠️ 7.13.0부터 더이상 사용되지 않음 필요하다면, path.data에 다중경로를 설정할 수 있습니다. 엘라스틱서치는 모든 제공되는 경로 전반적으로 노드의 데이터를 저장하지만 각각 샤드는 동일한 경로에 저장합니다.\n엘라스틱서치는 노드의 데이터 경로에 샤드의 균형을 맞추지는 않습니다. 단일 경로에 높은 디스크 사용률은 노드 전체에 높은 디스크 사용량 워터마크를 발생시킵니다. 발생된다면 엘라스틱서치는 해당 노드의 다른 경로에 충분한 디스크 용량이 있더라도 샤드를 추가하지 않습니다. 추가적인 디스크 공간이 필요하다면, 추가 데이터 경로보다는 신규 노드를 추천합니다.\nUnix 시스템Windows 리눅스와 macOS 설치는 path.data에 Unix 스타일의 다중 경로를 지원합니다.\npath: data: - /mnt/elasticsearch_1 - /mnt/elasticsearch_2 - /mnt/elasticsearch_3 Windows 설치는 path.data에 DOS의 다중 경로를 지원합니다.\npath: data: - \"C:\\\\Elastic\\\\Elasticsearch_1\" - \"E:\\\\Elastic\\\\Elasticsearch_2\" - \"F:\\\\Elastic\\\\Elasticsearch_3\" ","다중-데이터-경로에서-마이그레이션하기#다중 데이터 경로에서 마이그레이션하기":"다중 데이터 경로 지원은 7.13부터 사용되지 않으며 추후 릴리즈에서 삭제될 예정입니다.\n다중 데이터 경로대신 RAID와 같은 하드웨어 가상화 계층 또는 리눅스에서 논리 볼륨 관리자(LVM, Logical Volume Manager)나 윈도우의 저장소 공간(Storage Spaces)와 같은 소프트웨어 가상화 계층으로 다수의 디스크를 묶은 파일시스템을 생성할 수 있습니다. 하나의 장비에서 다수의 데이터 경로를 사용하고 싶다면 필히 데이터 경로마다 노드를 실행해야합니다.\n현재 고가용성 클러스터에 다중 데이터 경로를 사용하고 있다면 각각 노드에 단일 경로를 사용하도록 롤링 시작과 유사한 절차를 사용하여 중단시간 없이 설정을 마이그레이션 해야합니다. 각각 노드가 차례로 중단 되면서 단일 데이터 경로로 구성된 하나이상의 노드로 교체됩니다. 더 자세한 것은 현재 다중 데이터 경로를 가지고 있는 각각의 노드에 대하여 아래 프로세스를 수행해야 합니다. 원칙적으로 이 마이그레이션을 8.0으로 롤링업그레이드 할 때 가능하나, 단일 데이터 경로 구성 후 업그레이드 시작을 권장합니다.\n장애에 대비하여 데이터보호를 위해 스냅샷을 수행합니다.\n선택적으로, 할당 필터를 사용하여 대상 노드를 데이터에서 떼어놓습니다.\nPUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.exclude._name\": \"target-node-name\" } } 할당 보기 API를 통해 이 데이터 마이그레이션 처리과정을 추적할 수 있습니다. 일부 샤드가 마이그레이션이 안되면 클러스터 할당 설명 API를 통해 왜 안되는지 확인이 가능합니다.\n대상 노드 중단을 포함하여 롤링 시작 프로세스의 단계를 따르세요.\n클러스터의 상태가 yello나 green이면 모든 샤드의 복제가 클러스터내 적어도 다른 노드 하나에 할당 되었다는 것 입니다.\n적용이 되면, 이전 단계에서 적용한 할당 필터를 제거합니다.\nPUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.exclude._name\": null } } 데이터 경로의 내용를 삭제하여 중지된 노드가 보유한 데이터를 폐기해야합니다.\n저장소를 재구성합니다. 예로, LVM이나 저장소 공간을 사용한 단일 파일시스템으로 디스크를 결합합니다. 재구성된 저장소에 보유한 데이터를 위한 충분한 공간이 있는지 확인합니다.\nelasitcsearch.yml 파일의 path.data 설정을 조정하여 노드를 재구성합니다. 필요하면 분리된 데이터 경로를 path.data로 설정하여 추가적인 노드를 설치합니다.\n새 노드를 시작하고 롤링 시작 절차의 나머지를 따라합니다.\n클러스터의 상태가 green임을 확인합니다. 그럼 모든 샤드가 할당되었습니다.\n다른 방법으로는 단일 데이터 경로 노드를 클러스터에 추가하고 할당 필터를 사용하여 새로운 노드에 데이터 전반을 마이그레이션하고 클러스터에서 이전 노드를 삭제합니다. 이 방법은 순간적으로 클러스터의 크기를 두배로 사용되기 때문에 가능한 용량이 있는지 확인하고 진행해야합니다.\n현재 다중 데이터 경로를 사용하고 클러스터의 가용성이 높지 않은 경우 스냅샷을 만들고 원하는 구성으로 클러스터를 생성한 뒤 복원하여 더 이상 사용하지 않는 구성으로 마이그레이션할 수 있습니다.","디스커버리-설정#디스커버리 설정":"두가지 중요한 디스커버리와 클러스터 형성 설정을 운영에 가기전에 구성해서 클러스터의 노드가 서로를 탐색하고 마스터 노드를 선출할 수 있게 합니다.\ndiscovery.seed_hosts\n네트워크 구성없이 즉시사용할 경우 엘라스틱서치는 사용가능한 루프백 주소에 바인딩되고 9300부터 9305까지 동일한 서버에 다른 노드가 실행중인지 로컬포트를 스캔합니다. 이 동작으로 다른 구성없이 자동 클러스터링 경험을 제공합니다.\n다른 호스트의 노드와의 클러스터 형태를 원한다면, 정적 discovery.seed_hosts 설정을 사용합니다. 이 설정은 [디스커버리 절차]의 시작이 가능한 살아있고 접근가능한 클러스터의 다른 마스터적격 노드 목록을 제공합니다. 이 설정은 클러스터의 마스터적격 노드의 모든 주소를 YAML 시퀀스나 목록으로 설정됩니다. 각각의 주소는 IP 주소 또는 DNS를 통해 한개이상의 IP 주소로 변경이 가능한 호스트명으로 구성됩니다.\ndiscovery.seed_hosts: - 192.168.1.10:9300 - 192.168.1.11 - seeds.mydomain.com - [0:0:0:0:0:ffff:c0a8:10c]:9301 포트는 기본값으로 9300입니다. 덮어쓸 수 있습니다. 호스트명이 다수의 IP로 해석이되면, 노드는 확인된 모든 주소에서 다른 노드를 찾으려고 시도합니다. IPv6 주소는 대괄호로 묶여야합니다. 마스터적격 노드가 고정된 이름 또는 주소가 없을 경우 주소를 동적으로 찾을 수 있도록 대안 호스트 제공자를 사용할 수 있습니다.\ncluster.initial_master_nodes\n엘라스틱서치가 최초 동작시, 클러스터 부트스트래핑 절차에서 최초선거의 투표가 집계되는 마스터적격 노드의 집합을 결정합니다.\n자동-부트스트래핑은 잠재적으로 불안정하기 때문에 운영모드의 새로운 클러스터를 시작할 때 가장 최초선거에서 투표 집계가 되는 마스터적격 노드를 명시적으로 목록화 해야합니다. 이 목록은 cluster.initial_master_nodes를 사용하여 설정할 수 있습니다.\n⚠️ 최초 클러스터 구성이 성공하면 각각 노드 구성의 cluster.initial_master_nodes 설정을 제거합니다. 클러스터를 재시작할 때 또는 기존 클러스터에 새로운 노드를 추가할 때 이 설정을 사용하면 안됩니다. discovery.seed_hosts: - 192.168.1.10:9300 - 192.168.1.11 - seeds.mydomain.com - [0:0:0:0:0:ffff:c0a8:10c]:9301 cluster.initial_master_nodes: - master-node-a - master-node-b - master-node-c 호스트명이 기본값으로 사용되는 node.name으로 초기 마스터노드를 식별합니다. cluster.initial_master_nodes의 값에 node.name가 명확히 일치해야합니다. 노드명에 master-node-a.example.com과 같은 정규화된 도메인명(FQDN, Fully-Qualified Domain Name)을 사용한다면 목록에 FQDN을 사용해야합니다. 반대로, node.name이 후행 한정자가 없는 순수 호스트이름인 경우 cluster.initial_master_nodes에서 후행 한정자를 생략해야합니다. 클러스터 부트스트래핑과 디스커버리와 클러스터 형성 설정을 참고하세요.","임시-디렉터리-설정#임시 디렉터리 설정":"엘라스틱서치는 시작스크립트에서 시스템 임시 디렉터리 하위에 바로 개별 임시 디렉터리를 생성하여 사용합니다.\n몇몇 리눅스 배포판에는 시스템유틸리티가 최근 접근하지 않았으면 /tmp에 파일과 디렉터리를 청소합니다. 이 동작은 엘라스틱서치가 동작중일 때 임시 디렉터리를 사용하는 기능이 장기간 사용되지 않으면 개별 임시 디렉터리 또한 삭제된다는 것 입니다. 이 기능이 나중에 다시 사용되면 개별 임시 디렉터리가 삭제됨으로 문제가 발생할 수 있습니다.\n.deb나 .rpm 패키지를 사용하여 엘라스틱서치를 설치하고 systemd 하위에 실행된다면 개별 임시 디렉터리는 정기적 정리대상에서 제외됩니다.\n장기간동안 리눅스나 맥의 .tar.gz 배포판을 실행한 경우 오래된 파일이나 디렉터리가 정리되는 경로 하위말고 다른 위치에 임시 디렉터리 생성을 고려해야합니다. 이 디렉터리는 엘라스틱서치를 실행한 사용자가 접근할 수 있도록 권한을 설정해야합니다. 그리고 엘라스틱서치가 실행할 때 $EV_TMDIR 환경변수로 설정하여 해당 위치를 가리킵니다.","클러스터-백업#클러스터 백업":"재해시 스냅샷은 영구적 데이터 손실을 방지합니다. 스냅샷 생명주기 관리는 클러스터의 일반적인 백업을 쉽게 생성하는 방법입니다. 자세한 정보는 스냅샷을 생성을 참고하세요.\n⚠️ 스냅샷을 만드는 것이 클러스터를 백업하는 안정적이고 지원되는 유일한 방법입니다. 노드의 데이터 디렉터리만 복사하는 것으로 엘라스틱서치 클러스터를 백업할 수 없습니다. 파일시스템수준 백업으로 데이터를 복구하는 방법을 지원하지 않습니다. 이러한 백업으로 클러스터를 복구하면 손상, 누락된 파일 또는 기타 데이터 불일치로 보고되어 실패하거나 성공으로 보이나 부분적 데이터 손실이 발생할 수 있습니다. ","클러스터명-설정#클러스터명 설정":"노드는 클러스터의 다른 모든 노드와 동일한 cluster.name을 공유할때만 합류할 수 있습니다. 기본값은 elasticsearch 입니다. 클러스터 목적에 따라 적절한 이름으로 변경도 가능합니다.\ncluster.name: logging-prod ⚠️ 절대로 다른 환경에서 동일한 클러스터명을 사용하지 마세요. 그렇지 않으면 원치않게 노드가 다른 클러스터로 합류할 수 있습니다. ℹ️ 클러스터명의 변경은 클러스터 전체 재시작이 필요합니다. ","힙크기-설정#힙크기 설정":"기본적으로 엘라스틱서치는 JVM 힙크기를 노드의 역할과 전체 메모리를 기반으로 자동설정합니다. 대부분의 운영환경에서는 기본크기를 권장합니다.\n필요하다면 기본크기를 JVM 힙 크기 설정으로 설정할 수 있습니다."},"title":"중요구성"},"/uml_tutorial/":{"data":{"":"","먼저-uml은-무엇인가#먼저\u0026hellip; UML은 무엇인가?":" https://sparxsystems.com/resources/tutorials/uml/part1.html\n통합 모델링 언어 (Unified Modeling Language, UML)은 객체지향 소프트웨어를 구축하는데 표준 요소로 빠르게 자리를 잡았습니다. 이 튜토리얼은 Enterprise Architect에서 제공하는 13가지의 UML 다이어그램에 대한 기술적 개요를 제공합니다. UML 2 문법은 UML 2.0 튜토리얼에서 상세하게 설명합니다.\n먼저… UML은 무엇인가? 객체 관리 그룹 (Object Management Group, OMG) 명세에 정의된 내용\n통합 모델링 언어(UML)는 소프트웨어 집약적인 시스템의 요소들을 시각화, 명세화, 구축화, 문서화를 위한 그래픽적 언어입니다. UML은 비즈니스 프로세스, 시스템 기능 등과 같은 개념적 요소와 프로그래밍 언어 상태, 데이터베이스 스키마, 재사용가능 소프트웨어 구성요소 등과 같은 구체적인 요소를 포함하여 시스템의 청사진을 작성하는 표준적인 방법을 제공합니다.\n여기서 강조하는 중요한 점은 UML은 명세를 위한 언어이지 방법이나 절차가 아닙니다. UML은 소프트웨어 시스템을 정의하는데 사용됩니다. 시스템의 구성요소를 상세화, 문서화, 구축 등 청사진을 작성하는데 사용되는 언어 입니다. UML은 소프트웨어 개발 방법론 (래셔널 통합 프로세스(Rational Unified Process)와 같은)을 지원하는 다양한 방법으로 사용됩니다. 하지만 자체적으로 방법론이나 절차를 규정하지는 않습니다.\nUML은 다음 도메인에 대한 표기법과 의미를 정의합니다.\n사용자 상호작용 또는 유즈케이스 모델 - 시스템과 사용자간 범위 및 상호작용을 묘사합니다. 어떤 측면에서는 요구사항 모델에 해당합니다. 상호작용 또는 의사소통 모델 - 시스템의 객체들이 다른 객체들과 작업을 완료하기 위해 어떻게 상호작용하는지 묘사합니다. 상태 또는 동적 모델 - 상태 차트는 클래스들이 시간이 지남에 따라 가지게 되는 상태나 조건들을 묘사합니다. 행동 그래프는 구현할 시스템의 워크플로우를 묘사합니다. 논리적 또는 클래스 모델 - 시스템에서 만들 클래스와 객체를 묘사합니다. 물리적 컴포넌트 모델 - 시스템에서 만들 소프트웨어(때때로 하드웨어 컴포넌트 포함)를 묘사합니다. 물리적 배포 모델 - 하드웨어 아키텍처에서 물리적 아키텍처와 컴포넌트의 배포를 묘사합니다. 또한 특수한 필요에 따라 UML 확장을 위한 확장 메커니즘을 정의할 수 있습니다. (예로 들어, 비즈니스 프로세스 모델링 확장)\n튜토리얼 파트2에서는 실제 시스템을 정의하고 만드는데 UML을 어떻게 사용하는지 확장해서 설명해줍니다.\n또한 비즈니스 프로세스 모델링(PDF)도 참고하세요."},"title":"UML 튜토리얼"}}